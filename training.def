Bootstrap: docker
From: nvidia/cuda:12.4.1-devel-ubuntu24.04

%labels
    Author        Daniel Zhu
    Description   MV-MAE + DrQv2 + MJX + Madrona Training Environment (CUDA 12.4.1, offline deps + online JAX/Madrona)

%files
    . /opt/src/MV_MAE_Implementation

%post
    set -euo pipefail

    echo "=== [1] Base OS packages ==="
    apt-get update -y
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
        git build-essential cmake pkg-config curl ca-certificates \
        ffmpeg libavcodec60 libavdevice60 libavfilter9 libavformat60 \
        libswscale7 libswresample4 \
        xvfb x11-utils libx11-dev libxrandr-dev libxinerama-dev \
        libxcursor-dev libxi-dev mesa-common-dev \
        libegl1 libegl-dev gpg lsb-release \
        python3 python3-venv python3-pip python3-dev
    rm -rf /var/lib/apt/lists/*

    echo "=== [2] Python venv ==="
    python3 -m venv /opt/mvmae_venv
    . /opt/mvmae_venv/bin/activate
    python -m pip install -U pip setuptools wheel uv

    echo "=== [3] Offline wheelhouse bulk deps ==="
    export TMPDIR=/opt/pip-tmp
    export PIP_CACHE_DIR=/opt/pip-cache
    export PIP_DISABLE_PIP_VERSION_CHECK=1
    export PIP_NO_INDEX=1
    mkdir -p /opt/pip-tmp /opt/pip-cache

    REQ=/opt/src/MV_MAE_Implementation/requirements.txt
    WHL=/opt/src/MV_MAE_Implementation/wheelhouse

    test -d "$WHL" || (echo "[ERROR] Missing wheelhouse at $WHL" && exit 3)
    test -f "$REQ" || (echo "[ERROR] Missing requirements.txt at $REQ" && exit 2)

    echo "=== [4] Install deps offline ==="
    python -m pip install --no-index --find-links "$WHL" -r "$REQ"

    echo "=== [5] Install JAX GPU (online) ==="
    unset PIP_NO_INDEX
    # This is the most stable install route for JAX GPU wheels.
    uv pip install --upgrade "jax[cuda12]==0.4.36"

    echo "=== [6] Build Madrona-MJX ==="
    rm -rf /opt/madrona_mjx
    cd /opt
    git clone --branch geom_quat https://github.com/shacklettbp/madrona_mjx.git madrona_mjx
    cd /opt/madrona_mjx
    git submodule update --init --recursive

    rm -rf build
    mkdir -p build
    cd build
    cmake .. \
      -DLOAD_VULKAN=OFF \
      -DCMAKE_BUILD_TYPE=Release \
      -DCMAKE_CUDA_ARCHITECTURES=89
    make -j"$(nproc)"

    echo "=== [7] Install madrona_mjx (one copy only) ==="
    cd /opt/madrona_mjx
    uv pip install -e .

    echo "=== [8] ldconfig for Madrona runtime libs ==="
    echo "/opt/madrona_mjx/build" > /etc/ld.so.conf.d/madrona_mjx.conf
    ldconfig

    echo "=== [9] Auto-enable venv inside container ==="
    mkdir -p /.singularity.d/env
    cat > /.singularity.d/env/99-autovenv.sh <<'EOS'
export VIRTUAL_ENV=/opt/mvmae_venv
export PATH="$VIRTUAL_ENV/bin:$PATH"
export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
EOS
    chmod 644 /.singularity.d/env/99-autovenv.sh

    echo "=== Build Completed Successfully ==="

%environment
    export DISPLAY=:1
    export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
    export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda"
    # Critical: include CUDA targets dir (nvJitLink etc live here on many images)
    export LD_LIBRARY_PATH="/opt/madrona_mjx/build:/usr/local/cuda/lib64:/usr/local/cuda/targets/x86_64-linux/lib:${LD_LIBRARY_PATH}"

%runscript
    set -euo pipefail
    . /opt/mvmae_venv/bin/activate
    cd /workspace 2>/dev/null || cd /opt/src

    echo "=== [sanity] python/jax/jaxlib ==="
    python -c "import sys,jax,jaxlib; print('py',sys.version); print('jax',jax.__version__,'jaxlib',jaxlib.__version__); print('devices',jax.devices())"

    echo "=== [sanity] madrona .so path ==="
    python -c "import madrona_mjx._madrona_mjx_batch_renderer as br; import os; print('so',br.__file__); print('mtime',os.path.getmtime(br.__file__))"

    echo "[MVMAE] Running training script..."
    exec python -m MV_MAE_Implementation.execute "$@"

%help
    Build:
      apptainer build training.sif training.def
    Run:
      apptainer run --nv --cleanenv --bind "$PWD:/workspace" training.sif
