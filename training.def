Bootstrap: docker
From: nvidia/cuda:12.8.0-devel-ubuntu24.04

%labels
    Author        Daniel Zhu
    Description   MV-MAE + DrQv2 + MJX + Madrona Training Environment (CUDA 12.8, Offline)

%files
    . /opt/src/MV_MAE_Implementation

%post
    set -e

    echo "=== [1] Installing base OS packages ==="
    apt-get update -y
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
        git build-essential cmake pkg-config curl ca-certificates \
        ffmpeg libavcodec60 libavdevice60 libavfilter9 libavformat60 \
        libswscale7 libswresample4 \
        xvfb x11-utils libx11-dev libxrandr-dev libxinerama-dev \
        libxcursor-dev libxi-dev mesa-common-dev \
        libegl1 libegl-dev gpg lsb-release \
        python3 python3-venv python3-pip python3-dev
    rm -rf /var/lib/apt/lists/*

    echo "=== [2] Creating Python venv ==="
    python3 -m venv /opt/mvmae_venv
    . /opt/mvmae_venv/bin/activate
    python -m pip install -U pip setuptools wheel uv

    echo "=== [3] Configure offline wheelhouse ==="
    export TMPDIR=/opt/pip-tmp
    export PIP_CACHE_DIR=/opt/pip-cache
    export PIP_DISABLE_PIP_VERSION_CHECK=1
    export PIP_NO_INDEX=1

    mkdir -p /opt/pip-tmp /opt/pip-cache

    REQ=/opt/src/MV_MAE_Implementation/requirements.txt
    WHL=/opt/src/MV_MAE_Implementation/wheelhouse

    if [ ! -d "$WHL" ]; then echo "Missing wheelhouse"; exit 3; fi
    if [ ! -f "$REQ" ]; then echo "Missing requirements.txt"; exit 2; fi

    echo "=== [4] Installing Python deps (offline) ==="
    python -m pip install --find-links "$WHL" --no-index -r "$REQ"

    echo "=== [5] Build Madrona-MJX (geom_quat) ==="
    # Clean any previous partial clone from earlier builds
    rm -rf /opt/madrona_mjx
    cd /opt
    git clone --branch geom_quat https://github.com/shacklettbp/madrona_mjx.git madrona_mjx
    cd /opt/madrona_mjx
    echo "[post] Running: git submodule update --init --recursive"
    git submodule update --init --recursive
    mkdir -p build
    cd build
    cmake .. -DLOAD_VULKAN=OFF
    make -j"$(nproc)"
    cd ..
    uv pip install -e .

    echo "=== [6] Install CUDA 12.8 pinned NVIDIA libs ==="
    cat >/tmp/nvidia_cuda12_12.8.txt <<'REQ'
nvidia-cublas-cu12==12.8.3.14
nvidia-cuda-cupti-cu12==12.8.57
nvidia-cuda-nvcc-cu12==12.8.93
nvidia-cuda-nvrtc-cu12==12.8.61
nvidia-cuda-runtime-cu12==12.8.57
nvidia-cudnn-cu12==9.7.1.26
nvidia-cufft-cu12==11.3.3.41
nvidia-cufile-cu12==1.13.0.11
nvidia-curand-cu12==10.3.9.55
nvidia-cusolver-cu12==11.7.2.55
nvidia-cusparse-cu12==12.5.7.53
nvidia-cusparselt-cu12==0.6.3
nvidia-nccl-cu12==2.26.2
nvidia-nvjitlink-cu12==12.8.61
nvidia-nvtx-cu12==12.8.55
REQ

    uv pip uninstall -y $(grep ^nvidia /tmp/nvidia_cuda12_12.8.txt | cut -d= -f1) || true
    uv pip install -r /tmp/nvidia_cuda12_12.8.txt

    echo "=== [7] Installing JAX 0.4.36 (cuda12_local backend) ==="
    uv pip install --no-index --find-links "$WHL" jax==0.4.36 jaxlib==0.4.36

    echo "=== [8] Auto-enable venv inside container ==="
    mkdir -p /.singularity.d/env
    cat > /.singularity.d/env/99-autovenv.sh <<'EOS'
export VIRTUAL_ENV=/opt/mvmae_venv
export PATH="$VIRTUAL_ENV/bin:$PATH"
export PYTHONPATH="/opt/src:${PYTHONPATH}"
EOS
    chmod 644 /.singularity.d/env/99-autovenv.sh

    echo "=== Build Completed Successfully ==="


%environment
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export DISPLAY=:1
    export HF_TOKEN=${HF_TOKEN:-}
    export WANDB_API_KEY=${WANDB_API_KEY:-}


%runscript
    if command -v nvidia-smi >/dev/null 2>&1; then
        echo "GPU:"
        nvidia-smi
    fi

    . /opt/mvmae_venv/bin/activate
    cd /opt/src

    echo "[MVMAE] Running training script..."
    exec python -m MV_MAE_Implementation.train_drqv2_mujoco "$@"


%help
    Offline JAX+CUDA12.8, Madrona-MJX, MV-MAE / DrQv2 training container.
    Build:
      apptainer build training.sif training.def
    Run:
      apptainer run --nv training.sif
    Exec:
      apptainer exec --nv training.sif python3
