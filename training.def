Bootstrap: docker
From: nvidia/cuda:12.5.1-devel-ubuntu24.04

%labels
    Author        Daniel Zhu
    Description   MV-MAE + DrQv2 + MJX + Madrona Training Environment (CUDA 12.5.1, Offline bulk deps + online JAX GPU)

%files
    . /opt/src/MV_MAE_Implementation

%post
    set -e

    echo "=== [1] Installing base OS packages ==="
    apt-get update -y
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
        git build-essential cmake pkg-config curl ca-certificates \
        ffmpeg libavcodec60 libavdevice60 libavfilter9 libavformat60 \
        libswscale7 libswresample4 \
        xvfb x11-utils libx11-dev libxrandr-dev libxinerama-dev \
        libxcursor-dev libxi-dev mesa-common-dev \
        libegl1 libegl-dev gpg lsb-release \
        python3 python3-venv python3-pip python3-dev
    rm -rf /var/lib/apt/lists/*

    echo "=== [2] Creating Python venv ==="
    python3 -m venv /opt/mvmae_venv
    . /opt/mvmae_venv/bin/activate
    python3 -m pip install -U pip setuptools wheel uv

    echo "=== [3] Configure offline wheelhouse for bulk deps ==="
    export TMPDIR=/opt/pip-tmp
    export PIP_CACHE_DIR=/opt/pip-cache
    export PIP_DISABLE_PIP_VERSION_CHECK=1
    export PIP_NO_INDEX=1
    mkdir -p /opt/pip-tmp /opt/pip-cache

    REQ=/opt/src/MV_MAE_Implementation/requirements.txt
    WHL=/opt/src/MV_MAE_Implementation/wheelhouse

    if [ ! -d "$WHL" ]; then
        echo "[ERROR] Missing wheelhouse at $WHL"
        exit 3
    fi
    if [ ! -f "$REQ" ]; then
        echo "[ERROR] Missing requirements.txt at $REQ"
        exit 2
    fi

    echo "=== [4] Installing Python deps (offline from wheelhouse) ==="
    python3 -m pip install --no-index --find-links "$WHL" -r "$REQ"

    echo "=== [4b] Ensure pip doesn't later override torch/torchvision from PyPI ==="
    export PIP_NO_BUILD_ISOLATION=1

    echo "=== [5] Installing JAX 0.4.36 + CUDA12 plugin/pjrt explicitly ==="
    unset PIP_NO_INDEX
    uv pip install --upgrade \
      "jax==0.4.36" \
      "jaxlib==0.4.36" \
      "jax-cuda12-plugin==0.4.36" \
      "jax-cuda12-pjrt==0.4.36"

    echo "=== [5b] Build-time JAX GPU sanity check (should see a CudaDevice) ==="
    python3 - <<'PY'
import os
os.environ["JAX_PLATFORMS"] = "cuda,cpu"
import jax
print("jax:", jax.__version__)
print("devices:", jax.devices())
PY

    echo "=== [6] Build Madrona-MJX (geom_quat) ==="
    rm -rf /opt/madrona_mjx
    cd /opt
    git clone --branch geom_quat https://github.com/shacklettbp/madrona_mjx.git madrona_mjx
    cd /opt/madrona_mjx
    echo "[post] Running: git submodule update --init --recursive"
    git submodule update --init --recursive

    mkdir -p build
    cd build
    cmake .. -DLOAD_VULKAN=OFF
    make -j"$(nproc)"
    cd ..

    # Editable install so Python can import madrona_mjx
    uv pip install -e .

    echo "=== [6c] Remove any TOP-LEVEL _madrona_* from site-packages (must not exist) ==="
    python3 - <<'PY'
import site, glob, os, sys, importlib.util

paths = []
try:
    paths += site.getsitepackages()
except Exception:
    pass
paths += [p for p in sys.path if p and ("site-packages" in p or "dist-packages" in p)]
paths = list(dict.fromkeys(paths))  # dedupe, preserve order

print("candidate python package dirs:")
for p in paths:
    print("  -", p)

removed = 0
for sp in paths:
    for pat in ("_madrona_mjx_batch_renderer*.so", "_madrona_mjx_visualizer*.so"):
        for f in glob.glob(os.path.join(sp, pat)):
            try:
                os.remove(f)
                print("removed:", f)
                removed += 1
            except FileNotFoundError:
                pass

top_br = importlib.util.find_spec("_madrona_mjx_batch_renderer")
top_vz = importlib.util.find_spec("_madrona_mjx_visualizer")
print("top-level batch:", None if top_br is None else top_br.origin)
print("top-level viz  :", None if top_vz is None else top_vz.origin)
assert top_br is None and top_vz is None, "FATAL: top-level _madrona_* still present"
print("removed files:", removed)
PY
echo "==========================================================================="

    # IMPORTANT: DO NOT copy _madrona_* into site-packages (prevents nanobind double-load).
    # Keep extensions only under madrona_mjx package imports.

    echo "/opt/madrona_mjx/build" > /etc/ld.so.conf.d/madrona_mjx.conf
    ldconfig

    echo "=== [6b] Build-time Madrona import sanity check (package-only) ==="
    python3 - <<'PY'
import importlib.util
import madrona_mjx, madrona_mjx.renderer
print("madrona_mjx:", madrona_mjx.__file__)
print("renderer   :", madrona_mjx.renderer.__file__)
print("top-level _madrona batch:", importlib.util.find_spec("_madrona_mjx_batch_renderer"))
print("pkg _madrona batch      :", importlib.util.find_spec("madrona_mjx._madrona_mjx_batch_renderer").origin)
PY

    echo "=== [7] Auto-enable venv inside container ==="
    mkdir -p /.singularity.d/env
    cat > /.singularity.d/env/99-autovenv.sh <<'EOS'
export VIRTUAL_ENV=/opt/mvmae_venv
export PATH="$VIRTUAL_ENV/bin:$PATH"
export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
# Strongly encourage GPU first; you can still fall back to CPU
export JAX_PLATFORMS="cuda,cpu"
export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda"
EOS
    chmod 644 /.singularity.d/env/99-autovenv.sh

    echo "=== Build Completed Successfully ==="

%environment
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export DISPLAY=:1
    export HF_TOKEN=${HF_TOKEN:-}
    export WANDB_API_KEY=${WANDB_API_KEY:-}
    export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
    export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda"
    export JAX_PLATFORMS="cuda,cpu"

%runscript
    if command -v nvidia-smi >/dev/null 2>&1; then
        echo "GPU:"
        nvidia-smi
    fi

    . /opt/mvmae_venv/bin/activate

    if [ -d "/workspace" ]; then
        cd /workspace
    else
        cd /opt/src
    fi

    echo "[MVMAE] Running training script..."
    exec python3 -m MV_MAE_Implementation.execute "$@"
