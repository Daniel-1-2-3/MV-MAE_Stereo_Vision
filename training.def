Bootstrap: docker
From: nvidia/cuda:12.5.1-devel-ubuntu24.04

%labels
    Author        Daniel Zhu
    Description   MV-MAE + DrQv2 + MJX + Madrona Training Environment (CUDA 12.5.1, Offline bulk deps + online JAX GPU)

%files
    . /opt/src/MV_MAE_Implementation

%post
    set -e

    echo "=== [1] Installing base OS packages ==="
    apt-get update -y
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
        git build-essential cmake pkg-config curl ca-certificates \
        ffmpeg libavcodec60 libavdevice60 libavfilter9 libavformat60 \
        libswscale7 libswresample4 \
        xvfb x11-utils libx11-dev libxrandr-dev libxinerama-dev \
        libxcursor-dev libxi-dev mesa-common-dev \
        libegl1 libegl-dev gpg lsb-release \
        python3 python3-venv python3-pip python3-dev
    rm -rf /var/lib/apt/lists/*

    echo "=== [2] Creating Python venv ==="
    python3 -m venv /opt/mvmae_venv
    . /opt/mvmae_venv/bin/activate
    python3 -m pip install -U pip setuptools wheel uv

    echo "=== [3] Configure offline wheelhouse for bulk deps ==="
    export TMPDIR=/opt/pip-tmp
    export PIP_CACHE_DIR=/opt/pip-cache
    export PIP_DISABLE_PIP_VERSION_CHECK=1
    export PIP_NO_INDEX=1
    mkdir -p /opt/pip-tmp /opt/pip-cache

    REQ=/opt/src/MV_MAE_Implementation/requirements.txt
    WHL=/opt/src/MV_MAE_Implementation/wheelhouse

    if [ ! -d "$WHL" ]; then
        echo "[ERROR] Missing wheelhouse at $WHL"
        exit 3
    fi
    if [ ! -f "$REQ" ]; then
        echo "[ERROR] Missing requirements.txt at $REQ"
        exit 2
    fi

    echo "=== [4] Installing Python deps (offline from wheelhouse) ==="
    python3 -m pip install --no-index --find-links "$WHL" -r "$REQ"

    echo "=== [4b] Ensure pip doesn't later override torch/torchvision from PyPI ==="
    export PIP_NO_BUILD_ISOLATION=1

    echo "=== [5] Installing JAX 0.4.36 + CUDA12 plugin/pjrt explicitly ==="
    unset PIP_NO_INDEX
    uv pip install --upgrade \
      "jax==0.4.36" \
      "jaxlib==0.4.36" \
      "jax-cuda12-plugin==0.4.36" \
      "jax-cuda12-pjrt==0.4.36"

    echo "=== [5b] Build-time JAX sanity check (NO GPU) ==="
    python3 - <<'PY'
import jax, jaxlib
print("jax:", jax.__version__)
print("jaxlib:", jaxlib.__version__)
PY

    echo "=== [6] Build Madrona-MJX (geom_quat) ==="
    rm -rf /opt/madrona_mjx
    cd /opt
    git clone --branch geom_quat https://github.com/shacklettbp/madrona_mjx.git madrona_mjx
    cd /opt/madrona_mjx
    echo "[post] Running: git submodule update --init --recursive"
    git submodule update --init --recursive

    mkdir -p build
    cd build
    cmake .. -DLOAD_VULKAN=OFF
    make -j"$(nproc)"
    cd ..

    # Editable install so Python can import madrona_mjx
    uv pip install -e .

    echo "=== [6c] Remove any TOP-LEVEL _madrona_* from site-packages (must not exist) ==="
    python3 - <<'PY'
import site, glob, os, sys, importlib.util

paths = []
try:
    paths += site.getsitepackages()
except Exception:
    pass
paths += [p for p in sys.path if p and ("site-packages" in p or "dist-packages" in p)]
paths = list(dict.fromkeys(paths))  # dedupe, preserve order

print("candidate python package dirs:")
for p in paths:
    print("  -", p)

removed = 0
for sp in paths:
    for pat in ("_madrona_mjx_batch_renderer*.so", "_madrona_mjx_visualizer*.so"):
        for f in glob.glob(os.path.join(sp, pat)):
            try:
                os.remove(f)
                print("removed:", f)
                removed += 1
            except FileNotFoundError:
                pass

top_br = importlib.util.find_spec("_madrona_mjx_batch_renderer")
top_vz = importlib.util.find_spec("_madrona_mjx_visualizer")
print("top-level batch:", None if top_br is None else top_br.origin)
print("top-level viz  :", None if top_vz is None else top_vz.origin)
assert top_br is None and top_vz is None, "FATAL: top-level _madrona_* still present"
print("removed files:", removed)
PY
    echo "==========================================================================="

    # IMPORTANT: DO NOT copy _madrona_* into site-packages (prevents nanobind double-load).
    # Keep extensions only under madrona_mjx package imports.

    echo "/opt/madrona_mjx/build" > /etc/ld.so.conf.d/madrona_mjx.conf
    ldconfig

    echo "=== [6b] Build-time Madrona sanity check (NO GPU / NO libcuda) ==="
    python3 - <<'PY'
import site, glob, os, importlib.util

sp = site.getsitepackages()[0]
print("site-packages:", sp)

# 1) Must NOT have top-level nanobind modules in site-packages
tops = []
for pat in ("_madrona_mjx_batch_renderer*.so", "_madrona_mjx_visualizer*.so"):
    tops += glob.glob(os.path.join(sp, pat))
print("top-level _madrona_* in site-packages:", tops if tops else "(none)")
assert not tops, "FATAL: top-level _madrona_* present (double-load risk)"

# 2) Must have the built package extension present in /opt/madrona_mjx/build
pkg_br = glob.glob("/opt/madrona_mjx/build/_madrona_mjx_batch_renderer*.so")
pkg_vz = glob.glob("/opt/madrona_mjx/build/_madrona_mjx_visualizer*.so")
print("pkg build batch:", pkg_br[:1] if pkg_br else "(missing)")
print("pkg build viz  :", pkg_vz[:1] if pkg_vz else "(missing)")
assert pkg_br and pkg_vz, "FATAL: built madrona extensions missing from /opt/madrona_mjx/build"

# 3) Check python can locate the package source (won't import GPU libs)
spec = importlib.util.find_spec("madrona_mjx")
print("madrona_mjx spec:", None if spec is None else spec.origin)
assert spec is not None, "FATAL: madrona_mjx not importable as a package (spec not found)"
PY
    echo "=============================================================="


    echo "=== [7] Auto-enable venv inside container ==="
    mkdir -p /.singularity.d/env
    cat > /.singularity.d/env/99-autovenv.sh <<'EOS'
export VIRTUAL_ENV=/opt/mvmae_venv
export PATH="$VIRTUAL_ENV/bin:$PATH"
export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
# Strongly encourage GPU first; you can still fall back to CPU
export JAX_PLATFORMS="cuda,cpu"
export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda"
EOS
    chmod 644 /.singularity.d/env/99-autovenv.sh

    echo "=== Build Completed Successfully ==="

%environment
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export DISPLAY=:1
    export HF_TOKEN=${HF_TOKEN:-}
    export WANDB_API_KEY=${WANDB_API_KEY:-}
    export PYTHONPATH="/workspace:/workspace/MV_MAE_Implementation:/opt/src:${PYTHONPATH}"
    export XLA_FLAGS="--xla_gpu_cuda_data_dir=/usr/local/cuda"
    export JAX_PLATFORMS="cuda,cpu"

%runscript
    if command -v nvidia-smi >/dev/null 2>&1; then
        echo "GPU:"
        nvidia-smi
    fi

    . /opt/mvmae_venv/bin/activate

    if [ -d "/workspace" ]; then
        cd /workspace
    else
        cd /opt/src
    fi

    echo "[MVMAE] Running training script..."
    exec python3 -m MV_MAE_Implementation.execute "$@"
